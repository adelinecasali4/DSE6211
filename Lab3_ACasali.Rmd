---
title: "Lab 3"
author: "Adeline Casali"
date: "2024-02-01"
output: word_document
---

Data Pre-Processing for Keras and TensorFlow
```{r}
# Load libraries and data
library(dplyr)
library(caret)
data <- read.csv("lab_3_data.csv")

# Create testing and training sets
training_ind <- createDataPartition(data$lodgepole_pine, 
                                    p = 0.75, 
                                    list = FALSE, 
                                    times = 1)
training_set <- data[training_ind, ]
test_set <- data[-training_ind, ]

# Assessing, grouping, and factoring categorical variables
unique(training_set$wilderness_area)
unique(training_set$soil_type)

top_20_soil_types <- training_set %>% 
  group_by(soil_type) %>% 
  summarize(count = n()) %>% 
  arrange(desc(count)) %>%
  select(soil_type) %>% 
  top_n(20)

training_set$soil_type <- ifelse(training_set$soil_type %in% top_20_soil_types$soil_type, 
                                 training_set$soil_type, 
                                 "other")

training_set$wilderness_area <- factor(training_set$wilderness_area)
training_set$soil_type <- factor(training_set$soil_type)

class(training_set$wilderness_area)
class(training_set$soil_type)

levels(training_set$wilderness_area)
levels(training_set$soil_type)

# One-hot encoding the training set
onehot_encoder <- dummyVars(~ wilderness_area + soil_type, 
                            training_set[, c("wilderness_area", "soil_type")], 
                            levelsOnly = TRUE, 
                            fullRank = TRUE)

onehot_enc_training <- predict(onehot_encoder, 
                               training_set[, c("wilderness_area", "soil_type")])
training_set <- cbind(training_set, onehot_enc_training)

# One-hot encoding the test set
test_set$soil_type <- ifelse(test_set$soil_type %in% top_20_soil_types$soil_type, 
                             test_set$soil_type, 
                             "other")

test_set$wilderness_area <- factor(test_set$wilderness_area)
test_set$soil_type <- factor(test_set$soil_type)

onehot_enc_test <- predict(onehot_encoder, test_set[, c("wilderness_area", "soil_type")])
test_set <- cbind(test_set, onehot_enc_test)

# Scaling test and training sets
test_set[, -c(11:13)] <- scale(test_set[, -c(11:13)], 
                               center = apply(training_set[, -c(11:13)], 2, mean), 
                               scale = apply(training_set[, -c(11:13)], 2, sd))
training_set[, -c(11:13)] <- scale(training_set[, -c(11:13)])

# Convert data sets to tensors
training_features <- array(data = unlist(training_set[, -c(11:13)]), 
                           dim = c(nrow(training_set), 33))
training_labels <- array(data = unlist(training_set[, 13]), 
                         dim = c(nrow(training_set)))

test_features <- array(data = unlist(test_set[, -c(11:13)]), 
                           dim = c(nrow(test_set), 33))
test_labels <- array(data = unlist(test_set[, 13]), 
                         dim = c(nrow(test_set)))
```

1) Displaying the training and test features. 
```{r}
head(training_features)
head(test_features)
```

2) The rank of the tensor "training_features" is 2. The shape is 6537 x 33 (6537 observations and 33 features). It has 33 dimensions along the second axis. 
```{r}
rank_of_tensor <- length(dim(training_features))
shape_of_tensor <- dim(training_features)
dimensions_second_axis <- dim(training_features)[2]

print(paste("Rank of the tensor:", rank_of_tensor))
print(paste("Shape of the tensor:", paste(shape_of_tensor, collapse = "x")))
print(paste("Dimensions along the second axis:", dimensions_second_axis))
```

3) Scaling numerical variables is important when using machine learning methods such as neural networks that rely on gradient descent for optimization. It is also important when there is a distance associated with the variables so that one numerical variable doesn't dominate others simply because of its units. 
